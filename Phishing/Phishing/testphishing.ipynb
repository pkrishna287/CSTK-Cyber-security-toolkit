{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96deceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Link:https://practice.geeksforgeeks.org/contest/megajob-a-thon-hiring-challenge-freshers\n",
      "The URL 'https://practice.geeksforgeeks.org/contest/megajob-a-thon-hiring-challenge-freshers' is classified as phishing with probability 0.7754.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "def preprocess_and_extract_features(df):\n",
    "    # Step 1: Extract URL components (protocol, domain, path, query, fragment) for each URL\n",
    "    urls = [url for url in df['url']]\n",
    "    df['protocol'], df['domain'], df['path'], df['query'], df['fragment'] = zip(*[urllib.parse.urlsplit(x) for x in urls])\n",
    "\n",
    "    # Step 2: Define the needed columns and calculate features for each component\n",
    "    needed_cols = ['url', 'domain', 'path', 'query', 'fragment']\n",
    "    for col in needed_cols:\n",
    "        df[f'{col}_length'] = df[col].str.len()\n",
    "        df[f'qty_dot_{col}'] = df[[col]].applymap(lambda x: str.count(x, '.'))\n",
    "        df[f'qty_hyphen_{col}'] = df[[col]].applymap(lambda x: str.count(x, '-'))\n",
    "        df[f'qty_slash_{col}'] = df[[col]].applymap(lambda x: str.count(x, '/'))\n",
    "        df[f'qty_questionmark_{col}'] = df[[col]].applymap(lambda x: str.count(x, '?'))\n",
    "        df[f'qty_equal_{col}'] = df[[col]].applymap(lambda x: str.count(x, '='))\n",
    "        df[f'qty_at_{col}'] = df[[col]].applymap(lambda x: str.count(x, '@'))\n",
    "        df[f'qty_and_{col}'] = df[[col]].applymap(lambda x: str.count(x, '&'))\n",
    "        df[f'qty_exclamation_{col}'] = df[[col]].applymap(lambda x: str.count(x, '!'))\n",
    "        df[f'qty_space_{col}'] = df[[col]].applymap(lambda x: str.count(x, ' '))\n",
    "        df[f'qty_tilde_{col}'] = df[[col]].applymap(lambda x: str.count(x, '~'))\n",
    "        df[f'qty_comma_{col}'] = df[[col]].applymap(lambda x: str.count(x, ','))\n",
    "        df[f'qty_plus_{col}'] = df[[col]].applymap(lambda x: str.count(x, '+'))\n",
    "        df[f'qty_asterisk_{col}'] = df[[col]].applymap(lambda x: str.count(x, '*'))\n",
    "        df[f'qty_hashtag_{col}'] = df[[col]].applymap(lambda x: str.count(x, '#'))\n",
    "        df[f'qty_dollar_{col}'] = df[[col]].applymap(lambda x: str.count(x, '$'))\n",
    "        df[f'qty_percent_{col}'] = df[[col]].applymap(lambda x: str.count(x, '%'))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the trained RandomForestClassifier model\n",
    "rfc_model = pickle.load(open('E:/BTECH/cstk/Phishing-URL-Detection-main/code/rfc.pkl', 'rb'))\n",
    "\n",
    "def predict_phishing(url):\n",
    "    # Preprocess the input URL and extract features\n",
    "    data = {\n",
    "        'url': [url]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df_with_features = preprocess_and_extract_features(df)\n",
    "    df_with_features = df_with_features.drop(columns=['url', 'protocol', 'domain', 'path', 'query', 'fragment','qty_slash_domain', 'qty_questionmark_domain','qty_equal_domain', 'qty_at_domain', 'qty_and_domain',\n",
    "     'qty_exclamation_domain', 'qty_space_domain', 'qty_tilde_domain','qty_comma_domain', 'qty_plus_domain', \n",
    "     'qty_asterisk_domain','qty_hashtag_domain', 'qty_dollar_domain', 'qty_percent_domain', 'qty_questionmark_path', \n",
    "     'qty_hashtag_path', 'qty_hashtag_query', 'qty_at_fragment','qty_tilde_fragment', 'qty_plus_fragment'])\n",
    "    \n",
    "    # Scale the features using the same StandardScaler used during training\n",
    "    X_train = pd.read_csv('E:\\\\BTECH\\\\cstk\\\\Phishing-URL-Detection-main\\\\data\\\\url_updated.csv')\n",
    "    X_train = X_train.drop(columns=['url', 'protocol', 'domain', 'path', 'query', 'fragment','phishing'])\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    user_input_features_sc = ss.transform(df_with_features)\n",
    "\n",
    "    # Make predictions using the trained RandomForestClassifier\n",
    "    probability_scores = rfc_model.predict_proba(user_input_features_sc)\n",
    "\n",
    "    # Extract the probability of class 1 (phishing) for the URL\n",
    "    phishing_probability = probability_scores[0, 1]\n",
    "\n",
    "    # Set the threshold probability for classifying URLs as phishing or non-phishing\n",
    "\n",
    "    # Print the results\n",
    "    if phishing_probability >= 0.5:\n",
    "        print(f\"The URL '{url}' is classified as phishing with probability {phishing_probability:.4f}.\")\n",
    "    else:\n",
    "        print(f\"The URL '{url}' is classified as non-phishing \")\n",
    "\n",
    "# Example usage:\n",
    "url=input(\"Enter Link:\")\n",
    "#url = \"http://news.co.global.prod.fastly.net/NjFmMmFjOWMwZjMxMzZkZjBhYWJhZQ==/?type=ist&orders=780653221&auth=ODZlYWQxZTYwOTk0N2Q5OTQwN2FkYQ==\"\n",
    "predict_phishing(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a4a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rudra\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1348405b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Link:https://practice.geeksforgeeks.org/contest/megajob-a-thon-hiring-challenge-freshers\n",
      "The URL 'https://practice.geeksforgeeks.org/contest/megajob-a-thon-hiring-challenge-freshers' is classified as non-phishing \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "import pickle\n",
    "\n",
    "def preprocess_and_extract_features(df):\n",
    "    # Step 1: Extract URL components (protocol, domain, path, query, fragment) for each URL\n",
    "    urls = [url for url in df['url']]\n",
    "    df['protocol'], df['domain'], df['path'], df['query'], df['fragment'] = zip(*[urllib.parse.urlsplit(x) for x in urls])\n",
    "\n",
    "    # Step 2: Define the needed columns and calculate features for each component\n",
    "    needed_cols = ['url', 'domain', 'path', 'query', 'fragment']\n",
    "    for col in needed_cols:\n",
    "        df[f'{col}_length'] = df[col].str.len()\n",
    "        df[f'qty_dot_{col}'] = df[[col]].applymap(lambda x: str.count(x, '.'))\n",
    "        df[f'qty_hyphen_{col}'] = df[[col]].applymap(lambda x: str.count(x, '-'))\n",
    "        df[f'qty_slash_{col}'] = df[[col]].applymap(lambda x: str.count(x, '/'))\n",
    "        df[f'qty_questionmark_{col}'] = df[[col]].applymap(lambda x: str.count(x, '?'))\n",
    "        df[f'qty_equal_{col}'] = df[[col]].applymap(lambda x: str.count(x, '='))\n",
    "        df[f'qty_at_{col}'] = df[[col]].applymap(lambda x: str.count(x, '@'))\n",
    "        df[f'qty_and_{col}'] = df[[col]].applymap(lambda x: str.count(x, '&'))\n",
    "        df[f'qty_exclamation_{col}'] = df[[col]].applymap(lambda x: str.count(x, '!'))\n",
    "        df[f'qty_space_{col}'] = df[[col]].applymap(lambda x: str.count(x, ' '))\n",
    "        df[f'qty_tilde_{col}'] = df[[col]].applymap(lambda x: str.count(x, '~'))\n",
    "        df[f'qty_comma_{col}'] = df[[col]].applymap(lambda x: str.count(x, ','))\n",
    "        df[f'qty_plus_{col}'] = df[[col]].applymap(lambda x: str.count(x, '+'))\n",
    "        df[f'qty_asterisk_{col}'] = df[[col]].applymap(lambda x: str.count(x, '*'))\n",
    "        df[f'qty_hashtag_{col}'] = df[[col]].applymap(lambda x: str.count(x, '#'))\n",
    "        df[f'qty_dollar_{col}'] = df[[col]].applymap(lambda x: str.count(x, '$'))\n",
    "        df[f'qty_percent_{col}'] = df[[col]].applymap(lambda x: str.count(x, '%'))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the trained RandomForestClassifier model\n",
    "rfc_model = pickle.load(open('E:/BTECH/cstk/Phishing-URL-Detection-main/code/rfc.pkl', 'rb'))\n",
    "\n",
    "def predict_phishing(url):\n",
    "    # Preprocess the input URL and extract features\n",
    "    data = {\n",
    "        'url': [url]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df_with_features = preprocess_and_extract_features(df)\n",
    "    \n",
    "    # Drop columns not used during training\n",
    "    columns_to_drop = ['url', 'protocol', 'domain', 'path', 'query', 'fragment', 'qty_slash_domain', 'qty_questionmark_domain', 'qty_equal_domain', 'qty_at_domain', 'qty_and_domain', 'qty_exclamation_domain', 'qty_space_domain', 'qty_tilde_domain', 'qty_comma_domain', 'qty_plus_domain', 'qty_asterisk_domain', 'qty_hashtag_domain', 'qty_dollar_domain', 'qty_percent_domain', 'qty_questionmark_path', 'qty_hashtag_path', 'qty_hashtag_query', 'qty_at_fragment', 'qty_tilde_fragment', 'qty_plus_fragment']\n",
    "    df_with_features = df_with_features.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Make predictions using the trained RandomForestClassifier\n",
    "    probability_scores = rfc_model.predict_proba(df_with_features)\n",
    "\n",
    "    # Extract the probability of class 1 (phishing) for the URL\n",
    "    phishing_probability = probability_scores[0, 1]\n",
    "\n",
    "    # Set the threshold probability for classifying URLs as phishing or non-phishing\n",
    "\n",
    "    # Print the results\n",
    "    if phishing_probability >= 0.5:\n",
    "        print(f\"The URL '{url}' is classified as phishing with probability {phishing_probability:.4f}.\")\n",
    "    else:\n",
    "        print(f\"The URL '{url}' is classified as non-phishing \")\n",
    "\n",
    "# Example usage:\n",
    "url=input(\"Enter Link:\")\n",
    "#url = \"http://news.co.global.prod.fastly.net/NjFmMmFjOWMwZjMxMzZkZjBhYWJhZQ==/?type=ist&orders=780653221&auth=ODZlYWQxZTYwOTk0N2Q5OTQwN2FkYQ==\"\n",
    "predict_phishing(url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
